{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"service1906_1506.json\") as of:\n",
    "    data = json.load(of)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "computes = [c for c in data.keys() if c!=\"timespan\"]\n",
    "variables = [v for v in data[computes[0]] if v!='index' and v!='arrJob_scheduling']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c= compute-1-26\n",
      "v= arrTemperature\n"
     ]
    }
   ],
   "source": [
    "#Check empty array\n",
    "def getEmptyArr(data, c):\n",
    "    cObj = data[c]\n",
    "    cDf = pd.DataFrame()\n",
    "    cDf['compute'] = [c for _ in data['timespan']]\n",
    "    cDf['timespan'] = data['timespan']\n",
    "    for v in variables:\n",
    "        vArr = np.array(cObj[v])\n",
    "        if len(vArr)==0:\n",
    "            print('c=', c)\n",
    "            print('v=', v)\n",
    "for c in computes:\n",
    "    getEmptyArr(data, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addTarget(cDf, predictedVar, predictedStep, target):\n",
    "    cDf[target] = cDf[predictedVar].shift(-predictedStep)\n",
    "    cDf.dropna(inplace=True)\n",
    "    return cDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getComputeDf(data, c, predictedVar, predictedStep, target):\n",
    "    cObj = data[c]\n",
    "    cDf = pd.DataFrame()\n",
    "    cDf['compute'] = [c for _ in data['timespan']]\n",
    "    cDf['timespan'] = data['timespan']\n",
    "    for v in variables:\n",
    "        vArr = np.array(cObj[v])\n",
    "        if len(vArr)==0:\n",
    "            return None\n",
    "        else:\n",
    "            for i in range(len(vArr[0])):\n",
    "                cDf[v+str(i)] = vArr[:, i]\n",
    "    cDf['timespan'] = pd.to_datetime(cDf['timespan'])\n",
    "    return addTarget(cDf, predictedVar, predictedStep, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from IPython.display import FileLink\n",
    "import codecs, json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exportNPArrayToJson(a, fileName):\n",
    "    b = a.tolist()\n",
    "    json.dump(b, codecs.open(fileName, 'w', encoding='utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitTrainTest(predictedVar):\n",
    "    target = predictedVar + \"_target\"\n",
    "    predictedSteps = 4\n",
    "    df = pd.concat([x for x in [getComputeDf(data, c, predictedVar, predictedSteps, target) for c in computes] if type(x)!=\"NoneType\"])\n",
    "    \n",
    "    df = df.reset_index().drop('index', axis=1)\n",
    "    features = [x for x in df.columns if x not in ['compute', 'timespan', target]]\n",
    "        \n",
    "    X_dfs = []\n",
    "    y = []\n",
    "    numberOfSequences = 1\n",
    "    # generate training data.\n",
    "    for compute in computes:\n",
    "        cDf = df[df['compute']==compute]\n",
    "        if(len(cDf) > sequenceSteps):\n",
    "            randSteps = np.random.randint(0, len(cDf)-sequenceSteps, numberOfSequences)\n",
    "            for randStep in randSteps:\n",
    "                X_dfs.append(cDf.iloc[randStep:randStep+sequenceSteps])\n",
    "                y.append(X_dfs[-1][target].values[-1])\n",
    "\n",
    "    X_train_dfs, X_test_dfs, y_train, y_test = train_test_split(X_dfs, y, test_size=0.33)\n",
    "            \n",
    "    #Scale data\n",
    "\n",
    "    # combine the training data to create a scaler\n",
    "    train_dfs = pd.concat(X_train_dfs)\n",
    "\n",
    "    scaler = StandardScaler().fit(train_dfs[features].values)\n",
    "    \n",
    "    X_train = np.array([scaler.transform(item[features].values) for item in X_train_dfs])\n",
    "    X_test = np.array([scaler.transform(item[features].values) for item in X_test_dfs])\n",
    "    y_train = np.array(y_train)\n",
    "    y_test = np.array(y_test)\n",
    "    \n",
    "    exportNPArrayToJson(X_train, 'newData/'+target+'_X_train_HPCC_'+str(sequenceSteps)+'.json')\n",
    "    exportNPArrayToJson(X_test, 'newData/'+target+'_X_test_HPCC_'+str(sequenceSteps)+'.json')\n",
    "    exportNPArrayToJson(y_train, 'newData/'+target+'_y_train_HPCC_'+str(sequenceSteps)+'.json')\n",
    "    exportNPArrayToJson(y_test, 'newData/'+target+'_y_test_HPCC_'+str(sequenceSteps)+'.json')\n",
    "    \n",
    "    FileLink('newData/'+target+'_X_train_HPCC_'+str(sequenceSteps)+'.json')\n",
    "    FileLink('newData/'+target+'_X_test_HPCC_'+str(sequenceSteps)+'.json')\n",
    "    FileLink('newData/'+target+'_y_train_HPCC_'+str(sequenceSteps)+'.json')\n",
    "    FileLink('newData/'+target+'_y_test_HPCC_'+str(sequenceSteps)+'.json')\n",
    "    \n",
    "    return (X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import regularizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "import tensorflow as tf\n",
    "\n",
    "SEED = 1711\n",
    "import os\n",
    "import random as rn\n",
    "import numpy as np\n",
    "from tensorflow import set_random_seed\n",
    "\n",
    "os.environ['PYTHONHASHSEED']=str(SEED)\n",
    "np.random.seed(SEED)\n",
    "set_random_seed(SEED)\n",
    "rn.seed(SEED)\n",
    "\n",
    "from keras import backend as K\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)\n",
    "# from keras import backend as K\n",
    "# K.set_session(K.tf.Session(config=K.tf.ConfigProto(intra_op_parallelism_threads=36, inter_op_parallelism_threads=36)))\n",
    "\n",
    "\n",
    "def createModel(l1Nodes, l2Nodes, d1Nodes, d2Nodes, inputShape):\n",
    "    # input layer\n",
    "    lstm1 = LSTM(l1Nodes, input_shape=inputShape, return_sequences=True, kernel_regularizer=regularizers.l2(0.1))\n",
    "    do1 = Dropout(0.2)\n",
    "    \n",
    "    lstm2 = LSTM(l2Nodes, return_sequences=True, kernel_regularizer=regularizers.l2(0.1))\n",
    "    do2 = Dropout(0.2)\n",
    "    \n",
    "    flatten = Flatten()\n",
    "    \n",
    "    dense1 = Dense(d1Nodes, activation='relu')\n",
    "    do3 = Dropout(0.2)\n",
    "    \n",
    "    dense2 = Dense(d2Nodes, activation='relu')\n",
    "    do4 = Dropout(0.2)\n",
    "    \n",
    "    # output layer\n",
    "    outL = Dense(1, activation='relu')\n",
    "    # combine the layers\n",
    "#     layers = [lstm1, do1, lstm2, do2, dense1, do3, dense2, do4, outL]\n",
    "#     layers = [lstm1, lstm2, flatten,  dense1, dense2, outL]\n",
    "#     layers = [lstm1, flatten,  dense1, outL]\n",
    "    layers = [lstm1, lstm2, flatten,  dense1, dense2, outL]\n",
    "\n",
    "    # create the model\n",
    "    model = Sequential(layers)\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arrTemperature0\n",
      "2019-11-06 02:40:45.002642\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 249 samples, validate on 63 samples\n",
      "Epoch 1/40\n",
      "249/249 [==============================] - 1s 4ms/step - loss: 3560.6773 - val_loss: 3269.1982\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3269.19822, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_0_config_8_8_8_4_ts100.h5\n",
      "Epoch 2/40\n",
      "249/249 [==============================] - 0s 1ms/step - loss: 3560.5246 - val_loss: 3269.0454\n",
      "\n",
      "Epoch 00002: val_loss improved from 3269.19822 to 3269.04539, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_0_config_8_8_8_4_ts100.h5\n",
      "Epoch 3/40\n",
      "249/249 [==============================] - 0s 1ms/step - loss: 3560.3747 - val_loss: 3268.8999\n",
      "\n",
      "Epoch 00003: val_loss improved from 3269.04539 to 3268.89988, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_0_config_8_8_8_4_ts100.h5\n",
      "Epoch 4/40\n",
      "249/249 [==============================] - 0s 1ms/step - loss: 3560.2329 - val_loss: 3268.7632\n",
      "\n",
      "Epoch 00004: val_loss improved from 3268.89988 to 3268.76316, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_0_config_8_8_8_4_ts100.h5\n",
      "Epoch 5/40\n",
      "249/249 [==============================] - 0s 1ms/step - loss: 3560.0998 - val_loss: 3268.6350\n",
      "\n",
      "Epoch 00005: val_loss improved from 3268.76316 to 3268.63499, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_0_config_8_8_8_4_ts100.h5\n",
      "Epoch 6/40\n",
      "249/249 [==============================] - 0s 1ms/step - loss: 3559.9751 - val_loss: 3268.5154\n",
      "\n",
      "Epoch 00006: val_loss improved from 3268.63499 to 3268.51536, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_0_config_8_8_8_4_ts100.h5\n",
      "Epoch 7/40\n",
      "249/249 [==============================] - 0s 1ms/step - loss: 3559.8588 - val_loss: 3268.4033\n",
      "\n",
      "Epoch 00007: val_loss improved from 3268.51536 to 3268.40330, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_0_config_8_8_8_4_ts100.h5\n",
      "Epoch 8/40\n",
      "249/249 [==============================] - 0s 1ms/step - loss: 3559.7500 - val_loss: 3268.2986\n",
      "\n",
      "Epoch 00008: val_loss improved from 3268.40330 to 3268.29856, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_0_config_8_8_8_4_ts100.h5\n",
      "Epoch 9/40\n",
      "249/249 [==============================] - 0s 1ms/step - loss: 3559.6482 - val_loss: 3268.2009\n",
      "\n",
      "Epoch 00009: val_loss improved from 3268.29856 to 3268.20091, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_0_config_8_8_8_4_ts100.h5\n",
      "Epoch 10/40\n",
      "249/249 [==============================] - 0s 1ms/step - loss: 3559.5531 - val_loss: 3268.1091\n",
      "\n",
      "Epoch 00010: val_loss improved from 3268.20091 to 3268.10911, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_0_config_8_8_8_4_ts100.h5\n",
      "Epoch 11/40\n",
      "249/249 [==============================] - 0s 1ms/step - loss: 3559.4642 - val_loss: 3268.0237\n",
      "\n",
      "Epoch 00011: val_loss improved from 3268.10911 to 3268.02366, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_0_config_8_8_8_4_ts100.h5\n",
      "Epoch 12/40\n",
      "249/249 [==============================] - 0s 1ms/step - loss: 3559.3809 - val_loss: 3267.9436\n",
      "\n",
      "Epoch 00012: val_loss improved from 3268.02366 to 3267.94358, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_0_config_8_8_8_4_ts100.h5\n",
      "Epoch 13/40\n",
      "249/249 [==============================] - 0s 1ms/step - loss: 3559.3033 - val_loss: 3267.8689\n",
      "\n",
      "Epoch 00013: val_loss improved from 3267.94358 to 3267.86888, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_0_config_8_8_8_4_ts100.h5\n",
      "Epoch 14/40\n",
      "249/249 [==============================] - 0s 1ms/step - loss: 3559.2308 - val_loss: 3267.7993\n",
      "\n",
      "Epoch 00014: val_loss improved from 3267.86888 to 3267.79930, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_0_config_8_8_8_4_ts100.h5\n",
      "Epoch 15/40\n",
      "249/249 [==============================] - 0s 1ms/step - loss: 3559.1629 - val_loss: 3267.7339\n",
      "\n",
      "Epoch 00015: val_loss improved from 3267.79930 to 3267.73387, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_0_config_8_8_8_4_ts100.h5\n",
      "Epoch 16/40\n",
      "249/249 [==============================] - 0s 1ms/step - loss: 3559.0994 - val_loss: 3267.6726\n",
      "\n",
      "Epoch 00016: val_loss improved from 3267.73387 to 3267.67259, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_0_config_8_8_8_4_ts100.h5\n",
      "Epoch 17/40\n",
      "249/249 [==============================] - 0s 1ms/step - loss: 3559.0399 - val_loss: 3267.6155\n",
      "\n",
      "Epoch 00017: val_loss improved from 3267.67259 to 3267.61546, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_0_config_8_8_8_4_ts100.h5\n",
      "Epoch 18/40\n",
      "249/249 [==============================] - 0s 1ms/step - loss: 3558.9843 - val_loss: 3267.5620\n",
      "\n",
      "Epoch 00018: val_loss improved from 3267.61546 to 3267.56199, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_0_config_8_8_8_4_ts100.h5\n",
      "Epoch 19/40\n",
      "249/249 [==============================] - 0s 1ms/step - loss: 3558.9323 - val_loss: 3267.5119\n",
      "\n",
      "Epoch 00019: val_loss improved from 3267.56199 to 3267.51194, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_0_config_8_8_8_4_ts100.h5\n",
      "Epoch 20/40\n",
      "249/249 [==============================] - 0s 1ms/step - loss: 3558.8836 - val_loss: 3267.4651\n",
      "\n",
      "Epoch 00020: val_loss improved from 3267.51194 to 3267.46507, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_0_config_8_8_8_4_ts100.h5\n",
      "Epoch 21/40\n",
      "249/249 [==============================] - 0s 1ms/step - loss: 3558.8383 - val_loss: 3267.4216\n",
      "\n",
      "Epoch 00021: val_loss improved from 3267.46507 to 3267.42161, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_0_config_8_8_8_4_ts100.h5\n",
      "Epoch 22/40\n",
      "249/249 [==============================] - 0s 1ms/step - loss: 3558.7958 - val_loss: 3267.3806\n",
      "\n",
      "Epoch 00022: val_loss improved from 3267.42161 to 3267.38060, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_0_config_8_8_8_4_ts100.h5\n",
      "Epoch 23/40\n",
      "249/249 [==============================] - 0s 1ms/step - loss: 3558.7561 - val_loss: 3267.3428\n",
      "\n",
      "Epoch 00023: val_loss improved from 3267.38060 to 3267.34275, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_0_config_8_8_8_4_ts100.h5\n",
      "Epoch 24/40\n",
      "249/249 [==============================] - 0s 1ms/step - loss: 3558.7191 - val_loss: 3267.3071\n",
      "\n",
      "Epoch 00024: val_loss improved from 3267.34275 to 3267.30711, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_0_config_8_8_8_4_ts100.h5\n",
      "Epoch 25/40\n",
      "249/249 [==============================] - 0s 1ms/step - loss: 3558.6846 - val_loss: 3267.2739\n",
      "\n",
      "Epoch 00025: val_loss improved from 3267.30711 to 3267.27391, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_0_config_8_8_8_4_ts100.h5\n",
      "Epoch 26/40\n",
      "249/249 [==============================] - 0s 1ms/step - loss: 3558.6524 - val_loss: 3267.2429\n",
      "\n",
      "Epoch 00026: val_loss improved from 3267.27391 to 3267.24290, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_0_config_8_8_8_4_ts100.h5\n",
      "Epoch 27/40\n",
      "249/249 [==============================] - 0s 1ms/step - loss: 3558.6224 - val_loss: 3267.2141\n",
      "\n",
      "Epoch 00027: val_loss improved from 3267.24290 to 3267.21409, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_0_config_8_8_8_4_ts100.h5\n",
      "Epoch 28/40\n",
      "249/249 [==============================] - 0s 1ms/step - loss: 3558.5944 - val_loss: 3267.1872\n",
      "\n",
      "Epoch 00028: val_loss improved from 3267.21409 to 3267.18724, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_0_config_8_8_8_4_ts100.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/40\n",
      "249/249 [==============================] - 0s 1ms/step - loss: 3558.5683 - val_loss: 3267.1623\n",
      "\n",
      "Epoch 00029: val_loss improved from 3267.18724 to 3267.16233, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_0_config_8_8_8_4_ts100.h5\n",
      "Epoch 30/40\n",
      "249/249 [==============================] - 0s 1ms/step - loss: 3558.5440 - val_loss: 3267.1389\n",
      "\n",
      "Epoch 00030: val_loss improved from 3267.16233 to 3267.13890, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_0_config_8_8_8_4_ts100.h5\n",
      "Epoch 31/40\n",
      "249/249 [==============================] - 0s 1ms/step - loss: 3558.5214 - val_loss: 3267.1172\n",
      "\n",
      "Epoch 00031: val_loss improved from 3267.13890 to 3267.11717, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_0_config_8_8_8_4_ts100.h5\n",
      "Epoch 32/40\n",
      "249/249 [==============================] - 0s 1ms/step - loss: 3558.5005 - val_loss: 3267.0974\n",
      "\n",
      "Epoch 00032: val_loss improved from 3267.11717 to 3267.09739, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_0_config_8_8_8_4_ts100.h5\n",
      "Epoch 33/40\n",
      "249/249 [==============================] - 0s 1ms/step - loss: 3558.4810 - val_loss: 3267.0783\n",
      "\n",
      "Epoch 00033: val_loss improved from 3267.09739 to 3267.07835, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_0_config_8_8_8_4_ts100.h5\n",
      "Epoch 34/40\n",
      "249/249 [==============================] - 0s 1ms/step - loss: 3558.4630 - val_loss: 3267.0613\n",
      "\n",
      "Epoch 00034: val_loss improved from 3267.07835 to 3267.06126, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_0_config_8_8_8_4_ts100.h5\n",
      "Epoch 35/40\n",
      "249/249 [==============================] - 0s 1ms/step - loss: 3558.4461 - val_loss: 3267.0451\n",
      "\n",
      "Epoch 00035: val_loss improved from 3267.06126 to 3267.04515, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_0_config_8_8_8_4_ts100.h5\n",
      "Epoch 36/40\n",
      "249/249 [==============================] - 0s 1ms/step - loss: 3558.4305 - val_loss: 3267.0303\n",
      "\n",
      "Epoch 00036: val_loss improved from 3267.04515 to 3267.03025, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_0_config_8_8_8_4_ts100.h5\n",
      "Epoch 37/40\n",
      "249/249 [==============================] - 0s 1ms/step - loss: 3558.4160 - val_loss: 3267.0163\n",
      "\n",
      "Epoch 00037: val_loss improved from 3267.03025 to 3267.01634, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_0_config_8_8_8_4_ts100.h5\n",
      "Epoch 38/40\n",
      "249/249 [==============================] - 0s 1ms/step - loss: 3558.4026 - val_loss: 3267.0034\n",
      "\n",
      "Epoch 00038: val_loss improved from 3267.01634 to 3267.00340, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_0_config_8_8_8_4_ts100.h5\n",
      "Epoch 39/40\n",
      "249/249 [==============================] - 0s 1ms/step - loss: 3558.3902 - val_loss: 3266.9917\n",
      "\n",
      "Epoch 00039: val_loss improved from 3267.00340 to 3266.99168, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_0_config_8_8_8_4_ts100.h5\n",
      "Epoch 40/40\n",
      "249/249 [==============================] - 0s 1ms/step - loss: 3558.3787 - val_loss: 3266.9807\n",
      "\n",
      "Epoch 00040: val_loss improved from 3266.99168 to 3266.98069, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_0_config_8_8_8_4_ts100.h5\n",
      "63/63 [==============================] - 0s 3ms/step\n",
      "Train on 249 samples, validate on 63 samples\n",
      "Epoch 1/40\n",
      "249/249 [==============================] - 1s 4ms/step - loss: 3396.4042 - val_loss: 3812.3011\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3812.30112, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_1_config_8_8_8_4_ts100.h5\n",
      "Epoch 2/40\n",
      "249/249 [==============================] - 0s 1ms/step - loss: 3349.1351 - val_loss: 3752.0821\n",
      "\n",
      "Epoch 00002: val_loss improved from 3812.30112 to 3752.08206, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_1_config_8_8_8_4_ts100.h5\n",
      "Epoch 3/40\n",
      "249/249 [==============================] - 0s 1ms/step - loss: 3262.6796 - val_loss: 3644.8342\n",
      "\n",
      "Epoch 00003: val_loss improved from 3752.08206 to 3644.83419, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_1_config_8_8_8_4_ts100.h5\n",
      "Epoch 4/40\n",
      "249/249 [==============================] - 0s 1ms/step - loss: 3123.8654 - val_loss: 3464.1960\n",
      "\n",
      "Epoch 00004: val_loss improved from 3644.83419 to 3464.19600, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_1_config_8_8_8_4_ts100.h5\n",
      "Epoch 5/40\n",
      "249/249 [==============================] - 0s 1ms/step - loss: 2915.4329 - val_loss: 3169.2083\n",
      "\n",
      "Epoch 00005: val_loss improved from 3464.19600 to 3169.20831, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_1_config_8_8_8_4_ts100.h5\n",
      "Epoch 6/40\n",
      "249/249 [==============================] - 0s 1ms/step - loss: 2597.5826 - val_loss: 2673.9488\n",
      "\n",
      "Epoch 00006: val_loss improved from 3169.20831 to 2673.94878, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_1_config_8_8_8_4_ts100.h5\n",
      "Epoch 7/40\n",
      "249/249 [==============================] - 0s 1ms/step - loss: 2127.5576 - val_loss: 2028.0607\n",
      "\n",
      "Epoch 00007: val_loss improved from 2673.94878 to 2028.06065, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_1_config_8_8_8_4_ts100.h5\n",
      "Epoch 8/40\n",
      "249/249 [==============================] - 0s 1ms/step - loss: 1576.8834 - val_loss: 1300.0610\n",
      "\n",
      "Epoch 00008: val_loss improved from 2028.06065 to 1300.06104, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_1_config_8_8_8_4_ts100.h5\n",
      "Epoch 9/40\n",
      "249/249 [==============================] - 0s 1ms/step - loss: 948.2052 - val_loss: 674.5940\n",
      "\n",
      "Epoch 00009: val_loss improved from 1300.06104 to 674.59404, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_1_config_8_8_8_4_ts100.h5\n",
      "Epoch 10/40\n",
      "249/249 [==============================] - 0s 1ms/step - loss: 528.6260 - val_loss: 358.7460\n",
      "\n",
      "Epoch 00010: val_loss improved from 674.59404 to 358.74598, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_1_config_8_8_8_4_ts100.h5\n",
      "Epoch 11/40\n",
      "249/249 [==============================] - 0s 1ms/step - loss: 352.6144 - val_loss: 280.9229\n",
      "\n",
      "Epoch 00011: val_loss improved from 358.74598 to 280.92295, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_1_config_8_8_8_4_ts100.h5\n",
      "Epoch 12/40\n",
      "249/249 [==============================] - 0s 1ms/step - loss: 325.1859 - val_loss: 257.8479\n",
      "\n",
      "Epoch 00012: val_loss improved from 280.92295 to 257.84787, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_1_config_8_8_8_4_ts100.h5\n",
      "Epoch 13/40\n",
      "249/249 [==============================] - 0s 1ms/step - loss: 293.3786 - val_loss: 244.8261\n",
      "\n",
      "Epoch 00013: val_loss improved from 257.84787 to 244.82615, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_1_config_8_8_8_4_ts100.h5\n",
      "Epoch 14/40\n",
      "249/249 [==============================] - 0s 1ms/step - loss: 268.8489 - val_loss: 246.8226\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 244.82615\n",
      "Epoch 15/40\n",
      "249/249 [==============================] - 0s 1ms/step - loss: 253.9575 - val_loss: 241.7125\n",
      "\n",
      "Epoch 00015: val_loss improved from 244.82615 to 241.71249, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_1_config_8_8_8_4_ts100.h5\n",
      "Epoch 16/40\n",
      "249/249 [==============================] - 0s 1ms/step - loss: 240.5392 - val_loss: 227.8062\n",
      "\n",
      "Epoch 00016: val_loss improved from 241.71249 to 227.80624, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_1_config_8_8_8_4_ts100.h5\n",
      "Epoch 17/40\n",
      "249/249 [==============================] - 0s 1ms/step - loss: 226.5853 - val_loss: 207.0231\n",
      "\n",
      "Epoch 00017: val_loss improved from 227.80624 to 207.02313, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_1_config_8_8_8_4_ts100.h5\n",
      "Epoch 18/40\n",
      "249/249 [==============================] - 0s 1ms/step - loss: 212.1283 - val_loss: 191.4272\n",
      "\n",
      "Epoch 00018: val_loss improved from 207.02313 to 191.42719, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_1_config_8_8_8_4_ts100.h5\n",
      "Epoch 19/40\n",
      "249/249 [==============================] - 0s 1ms/step - loss: 197.0445 - val_loss: 179.5853\n",
      "\n",
      "Epoch 00019: val_loss improved from 191.42719 to 179.58526, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_1_config_8_8_8_4_ts100.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/40\n",
      "249/249 [==============================] - 0s 1ms/step - loss: 180.7689 - val_loss: 165.9074\n",
      "\n",
      "Epoch 00020: val_loss improved from 179.58526 to 165.90745, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_1_config_8_8_8_4_ts100.h5\n",
      "Epoch 21/40\n",
      "249/249 [==============================] - 0s 1ms/step - loss: 163.6723 - val_loss: 151.6869\n",
      "\n",
      "Epoch 00021: val_loss improved from 165.90745 to 151.68687, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_1_config_8_8_8_4_ts100.h5\n",
      "Epoch 22/40\n",
      "249/249 [==============================] - 0s 1ms/step - loss: 146.2477 - val_loss: 135.3898\n",
      "\n",
      "Epoch 00022: val_loss improved from 151.68687 to 135.38977, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_1_config_8_8_8_4_ts100.h5\n",
      "Epoch 23/40\n",
      "249/249 [==============================] - 0s 1ms/step - loss: 130.0271 - val_loss: 122.0576\n",
      "\n",
      "Epoch 00023: val_loss improved from 135.38977 to 122.05762, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_1_config_8_8_8_4_ts100.h5\n",
      "Epoch 24/40\n",
      "249/249 [==============================] - 0s 1ms/step - loss: 118.5778 - val_loss: 112.2338\n",
      "\n",
      "Epoch 00024: val_loss improved from 122.05762 to 112.23380, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_1_config_8_8_8_4_ts100.h5\n",
      "Epoch 25/40\n",
      "249/249 [==============================] - 0s 1ms/step - loss: 109.3980 - val_loss: 108.1820\n",
      "\n",
      "Epoch 00025: val_loss improved from 112.23380 to 108.18195, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_1_config_8_8_8_4_ts100.h5\n",
      "Epoch 26/40\n",
      "249/249 [==============================] - 0s 1ms/step - loss: 104.6875 - val_loss: 99.2831\n",
      "\n",
      "Epoch 00026: val_loss improved from 108.18195 to 99.28310, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_1_config_8_8_8_4_ts100.h5\n",
      "Epoch 27/40\n",
      "249/249 [==============================] - 0s 1ms/step - loss: 98.5518 - val_loss: 98.2829\n",
      "\n",
      "Epoch 00027: val_loss improved from 99.28310 to 98.28290, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_1_config_8_8_8_4_ts100.h5\n",
      "Epoch 28/40\n",
      "249/249 [==============================] - 0s 1ms/step - loss: 94.5849 - val_loss: 96.0019\n",
      "\n",
      "Epoch 00028: val_loss improved from 98.28290 to 96.00190, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_1_config_8_8_8_4_ts100.h5\n",
      "Epoch 29/40\n",
      "249/249 [==============================] - 0s 1ms/step - loss: 91.3717 - val_loss: 95.5191\n",
      "\n",
      "Epoch 00029: val_loss improved from 96.00190 to 95.51914, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_1_config_8_8_8_4_ts100.h5\n",
      "Epoch 30/40\n",
      "249/249 [==============================] - 0s 1ms/step - loss: 89.1562 - val_loss: 91.2687\n",
      "\n",
      "Epoch 00030: val_loss improved from 95.51914 to 91.26875, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_1_config_8_8_8_4_ts100.h5\n",
      "Epoch 31/40\n",
      "249/249 [==============================] - 0s 1ms/step - loss: 86.7948 - val_loss: 93.1154\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 91.26875\n",
      "Epoch 32/40\n",
      "249/249 [==============================] - 0s 1ms/step - loss: 85.0790 - val_loss: 93.2609\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 91.26875\n",
      "Epoch 33/40\n",
      "249/249 [==============================] - 0s 1ms/step - loss: 83.5677 - val_loss: 92.9743\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 91.26875\n",
      "Epoch 00033: early stopping\n",
      "63/63 [==============================] - 0s 5ms/step\n",
      "Train on 250 samples, validate on 62 samples\n",
      "Epoch 1/40\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3497.8260 - val_loss: 3492.3555\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3492.35551, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_2_config_8_8_8_4_ts100.h5\n",
      "Epoch 2/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 3485.1860 - val_loss: 3474.5071\n",
      "\n",
      "Epoch 00002: val_loss improved from 3492.35551 to 3474.50707, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_2_config_8_8_8_4_ts100.h5\n",
      "Epoch 3/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 3459.5630 - val_loss: 3439.4870\n",
      "\n",
      "Epoch 00003: val_loss improved from 3474.50707 to 3439.48701, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_2_config_8_8_8_4_ts100.h5\n",
      "Epoch 4/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 3410.7998 - val_loss: 3383.2397\n",
      "\n",
      "Epoch 00004: val_loss improved from 3439.48701 to 3383.23965, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_2_config_8_8_8_4_ts100.h5\n",
      "Epoch 5/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 3333.3400 - val_loss: 3293.1163\n",
      "\n",
      "Epoch 00005: val_loss improved from 3383.23965 to 3293.11631, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_2_config_8_8_8_4_ts100.h5\n",
      "Epoch 6/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 3213.2427 - val_loss: 3154.7622\n",
      "\n",
      "Epoch 00006: val_loss improved from 3293.11631 to 3154.76220, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_2_config_8_8_8_4_ts100.h5\n",
      "Epoch 7/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 3040.3848 - val_loss: 2958.0656\n",
      "\n",
      "Epoch 00007: val_loss improved from 3154.76220 to 2958.06561, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_2_config_8_8_8_4_ts100.h5\n",
      "Epoch 8/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 2797.5886 - val_loss: 2705.5829\n",
      "\n",
      "Epoch 00008: val_loss improved from 2958.06561 to 2705.58292, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_2_config_8_8_8_4_ts100.h5\n",
      "Epoch 9/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 2512.5515 - val_loss: 2403.1061\n",
      "\n",
      "Epoch 00009: val_loss improved from 2705.58292 to 2403.10611, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_2_config_8_8_8_4_ts100.h5\n",
      "Epoch 10/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 2156.1264 - val_loss: 2026.0237\n",
      "\n",
      "Epoch 00010: val_loss improved from 2403.10611 to 2026.02366, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_2_config_8_8_8_4_ts100.h5\n",
      "Epoch 11/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1696.3351 - val_loss: 1559.1315\n",
      "\n",
      "Epoch 00011: val_loss improved from 2026.02366 to 1559.13149, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_2_config_8_8_8_4_ts100.h5\n",
      "Epoch 12/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1137.3236 - val_loss: 1013.7944\n",
      "\n",
      "Epoch 00012: val_loss improved from 1559.13149 to 1013.79440, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_2_config_8_8_8_4_ts100.h5\n",
      "Epoch 13/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 640.0444 - val_loss: 547.6090\n",
      "\n",
      "Epoch 00013: val_loss improved from 1013.79440 to 547.60904, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_2_config_8_8_8_4_ts100.h5\n",
      "Epoch 14/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 292.7538 - val_loss: 225.9157\n",
      "\n",
      "Epoch 00014: val_loss improved from 547.60904 to 225.91574, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_2_config_8_8_8_4_ts100.h5\n",
      "Epoch 15/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 177.8381 - val_loss: 194.5526\n",
      "\n",
      "Epoch 00015: val_loss improved from 225.91574 to 194.55258, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_2_config_8_8_8_4_ts100.h5\n",
      "Epoch 16/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 186.4334 - val_loss: 184.8868\n",
      "\n",
      "Epoch 00016: val_loss improved from 194.55258 to 184.88682, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_2_config_8_8_8_4_ts100.h5\n",
      "Epoch 17/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 163.2510 - val_loss: 164.7431\n",
      "\n",
      "Epoch 00017: val_loss improved from 184.88682 to 164.74311, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_2_config_8_8_8_4_ts100.h5\n",
      "Epoch 18/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 143.0998 - val_loss: 161.8266\n",
      "\n",
      "Epoch 00018: val_loss improved from 164.74311 to 161.82662, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_2_config_8_8_8_4_ts100.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 137.2507 - val_loss: 158.9152\n",
      "\n",
      "Epoch 00019: val_loss improved from 161.82662 to 158.91519, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_2_config_8_8_8_4_ts100.h5\n",
      "Epoch 20/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 128.4189 - val_loss: 148.0633\n",
      "\n",
      "Epoch 00020: val_loss improved from 158.91519 to 148.06330, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_2_config_8_8_8_4_ts100.h5\n",
      "Epoch 21/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 120.6209 - val_loss: 138.7925\n",
      "\n",
      "Epoch 00021: val_loss improved from 148.06330 to 138.79253, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_2_config_8_8_8_4_ts100.h5\n",
      "Epoch 22/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 115.6508 - val_loss: 132.5776\n",
      "\n",
      "Epoch 00022: val_loss improved from 138.79253 to 132.57765, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_2_config_8_8_8_4_ts100.h5\n",
      "Epoch 23/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 110.6173 - val_loss: 129.1564\n",
      "\n",
      "Epoch 00023: val_loss improved from 132.57765 to 129.15637, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_2_config_8_8_8_4_ts100.h5\n",
      "Epoch 24/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 106.5285 - val_loss: 126.0384\n",
      "\n",
      "Epoch 00024: val_loss improved from 129.15637 to 126.03844, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_2_config_8_8_8_4_ts100.h5\n",
      "Epoch 25/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 103.6963 - val_loss: 123.5833\n",
      "\n",
      "Epoch 00025: val_loss improved from 126.03844 to 123.58334, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_2_config_8_8_8_4_ts100.h5\n",
      "Epoch 26/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 101.4487 - val_loss: 120.2981\n",
      "\n",
      "Epoch 00026: val_loss improved from 123.58334 to 120.29807, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_2_config_8_8_8_4_ts100.h5\n",
      "Epoch 27/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 98.9596 - val_loss: 115.4797\n",
      "\n",
      "Epoch 00027: val_loss improved from 120.29807 to 115.47975, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_2_config_8_8_8_4_ts100.h5\n",
      "Epoch 28/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 96.9771 - val_loss: 111.1084\n",
      "\n",
      "Epoch 00028: val_loss improved from 115.47975 to 111.10841, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_2_config_8_8_8_4_ts100.h5\n",
      "Epoch 29/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 95.2405 - val_loss: 108.3632\n",
      "\n",
      "Epoch 00029: val_loss improved from 111.10841 to 108.36316, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_2_config_8_8_8_4_ts100.h5\n",
      "Epoch 30/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 93.2369 - val_loss: 105.3613\n",
      "\n",
      "Epoch 00030: val_loss improved from 108.36316 to 105.36125, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_2_config_8_8_8_4_ts100.h5\n",
      "Epoch 31/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 91.3864 - val_loss: 101.1354\n",
      "\n",
      "Epoch 00031: val_loss improved from 105.36125 to 101.13543, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_2_config_8_8_8_4_ts100.h5\n",
      "Epoch 32/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 89.9075 - val_loss: 97.4976\n",
      "\n",
      "Epoch 00032: val_loss improved from 101.13543 to 97.49758, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_2_config_8_8_8_4_ts100.h5\n",
      "Epoch 33/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 88.3124 - val_loss: 94.9344\n",
      "\n",
      "Epoch 00033: val_loss improved from 97.49758 to 94.93440, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_2_config_8_8_8_4_ts100.h5\n",
      "Epoch 34/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 86.9210 - val_loss: 91.4367\n",
      "\n",
      "Epoch 00034: val_loss improved from 94.93440 to 91.43669, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_2_config_8_8_8_4_ts100.h5\n",
      "Epoch 35/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 85.5612 - val_loss: 89.0676\n",
      "\n",
      "Epoch 00035: val_loss improved from 91.43669 to 89.06755, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_2_config_8_8_8_4_ts100.h5\n",
      "Epoch 36/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 84.4411 - val_loss: 88.3713\n",
      "\n",
      "Epoch 00036: val_loss improved from 89.06755 to 88.37129, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_2_config_8_8_8_4_ts100.h5\n",
      "Epoch 37/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 83.3714 - val_loss: 84.7003\n",
      "\n",
      "Epoch 00037: val_loss improved from 88.37129 to 84.70029, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_2_config_8_8_8_4_ts100.h5\n",
      "Epoch 38/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 82.4229 - val_loss: 81.9830\n",
      "\n",
      "Epoch 00038: val_loss improved from 84.70029 to 81.98303, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_2_config_8_8_8_4_ts100.h5\n",
      "Epoch 39/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 81.5317 - val_loss: 80.1395\n",
      "\n",
      "Epoch 00039: val_loss improved from 81.98303 to 80.13947, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_2_config_8_8_8_4_ts100.h5\n",
      "Epoch 40/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 80.7967 - val_loss: 79.1664\n",
      "\n",
      "Epoch 00040: val_loss improved from 80.13947 to 79.16638, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_2_config_8_8_8_4_ts100.h5\n",
      "62/62 [==============================] - 1s 8ms/step\n",
      "Train on 250 samples, validate on 62 samples\n",
      "Epoch 1/40\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 3540.5466 - val_loss: 3319.1259\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3319.12590, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_3_config_8_8_8_4_ts100.h5\n",
      "Epoch 2/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 3521.7848 - val_loss: 3285.4257\n",
      "\n",
      "Epoch 00002: val_loss improved from 3319.12590 to 3285.42566, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_3_config_8_8_8_4_ts100.h5\n",
      "Epoch 3/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 3483.3343 - val_loss: 3219.7922\n",
      "\n",
      "Epoch 00003: val_loss improved from 3285.42566 to 3219.79224, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_3_config_8_8_8_4_ts100.h5\n",
      "Epoch 4/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 3413.2905 - val_loss: 3104.1495\n",
      "\n",
      "Epoch 00004: val_loss improved from 3219.79224 to 3104.14953, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_3_config_8_8_8_4_ts100.h5\n",
      "Epoch 5/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 3287.0023 - val_loss: 2899.7427\n",
      "\n",
      "Epoch 00005: val_loss improved from 3104.14953 to 2899.74267, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_3_config_8_8_8_4_ts100.h5\n",
      "Epoch 6/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 3056.7115 - val_loss: 2572.1235\n",
      "\n",
      "Epoch 00006: val_loss improved from 2899.74267 to 2572.12350, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_3_config_8_8_8_4_ts100.h5\n",
      "Epoch 7/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 2689.8488 - val_loss: 2169.7709\n",
      "\n",
      "Epoch 00007: val_loss improved from 2572.12350 to 2169.77094, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_3_config_8_8_8_4_ts100.h5\n",
      "Epoch 8/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 2246.4476 - val_loss: 1685.8016\n",
      "\n",
      "Epoch 00008: val_loss improved from 2169.77094 to 1685.80162, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_3_config_8_8_8_4_ts100.h5\n",
      "Epoch 9/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1686.1970 - val_loss: 1142.1051\n",
      "\n",
      "Epoch 00009: val_loss improved from 1685.80162 to 1142.10510, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_3_config_8_8_8_4_ts100.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1118.6581 - val_loss: 707.5143\n",
      "\n",
      "Epoch 00010: val_loss improved from 1142.10510 to 707.51430, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_3_config_8_8_8_4_ts100.h5\n",
      "Epoch 11/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 707.3657 - val_loss: 425.6585\n",
      "\n",
      "Epoch 00011: val_loss improved from 707.51430 to 425.65850, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_3_config_8_8_8_4_ts100.h5\n",
      "Epoch 12/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 452.9128 - val_loss: 290.7939\n",
      "\n",
      "Epoch 00012: val_loss improved from 425.65850 to 290.79395, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_3_config_8_8_8_4_ts100.h5\n",
      "Epoch 13/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 331.4429 - val_loss: 262.4015\n",
      "\n",
      "Epoch 00013: val_loss improved from 290.79395 to 262.40150, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_3_config_8_8_8_4_ts100.h5\n",
      "Epoch 14/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 295.1302 - val_loss: 258.7164\n",
      "\n",
      "Epoch 00014: val_loss improved from 262.40150 to 258.71644, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_3_config_8_8_8_4_ts100.h5\n",
      "Epoch 15/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 271.2393 - val_loss: 230.7105\n",
      "\n",
      "Epoch 00015: val_loss improved from 258.71644 to 230.71050, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_3_config_8_8_8_4_ts100.h5\n",
      "Epoch 16/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 245.6377 - val_loss: 200.9955\n",
      "\n",
      "Epoch 00016: val_loss improved from 230.71050 to 200.99548, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_3_config_8_8_8_4_ts100.h5\n",
      "Epoch 17/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 220.0255 - val_loss: 181.9342\n",
      "\n",
      "Epoch 00017: val_loss improved from 200.99548 to 181.93423, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_3_config_8_8_8_4_ts100.h5\n",
      "Epoch 18/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 194.8855 - val_loss: 163.5737\n",
      "\n",
      "Epoch 00018: val_loss improved from 181.93423 to 163.57374, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_3_config_8_8_8_4_ts100.h5\n",
      "Epoch 19/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 167.5527 - val_loss: 139.2325\n",
      "\n",
      "Epoch 00019: val_loss improved from 163.57374 to 139.23246, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_3_config_8_8_8_4_ts100.h5\n",
      "Epoch 20/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 150.0239 - val_loss: 136.6163\n",
      "\n",
      "Epoch 00020: val_loss improved from 139.23246 to 136.61628, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_3_config_8_8_8_4_ts100.h5\n",
      "Epoch 21/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 140.8928 - val_loss: 137.8818\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 136.61628\n",
      "Epoch 22/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 134.9729 - val_loss: 115.7829\n",
      "\n",
      "Epoch 00022: val_loss improved from 136.61628 to 115.78291, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_3_config_8_8_8_4_ts100.h5\n",
      "Epoch 23/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 122.6543 - val_loss: 111.8024\n",
      "\n",
      "Epoch 00023: val_loss improved from 115.78291 to 111.80237, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_3_config_8_8_8_4_ts100.h5\n",
      "Epoch 24/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 117.1055 - val_loss: 110.6646\n",
      "\n",
      "Epoch 00024: val_loss improved from 111.80237 to 110.66461, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_3_config_8_8_8_4_ts100.h5\n",
      "Epoch 25/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 112.1945 - val_loss: 104.4066\n",
      "\n",
      "Epoch 00025: val_loss improved from 110.66461 to 104.40661, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_3_config_8_8_8_4_ts100.h5\n",
      "Epoch 26/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 108.7504 - val_loss: 100.0405\n",
      "\n",
      "Epoch 00026: val_loss improved from 104.40661 to 100.04049, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_3_config_8_8_8_4_ts100.h5\n",
      "Epoch 27/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 105.3869 - val_loss: 96.2284\n",
      "\n",
      "Epoch 00027: val_loss improved from 100.04049 to 96.22835, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_3_config_8_8_8_4_ts100.h5\n",
      "Epoch 28/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 103.9028 - val_loss: 102.7944\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 96.22835\n",
      "Epoch 29/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 99.6233 - val_loss: 90.2028\n",
      "\n",
      "Epoch 00029: val_loss improved from 96.22835 to 90.20281, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_3_config_8_8_8_4_ts100.h5\n",
      "Epoch 30/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 97.1996 - val_loss: 88.2974\n",
      "\n",
      "Epoch 00030: val_loss improved from 90.20281 to 88.29740, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_3_config_8_8_8_4_ts100.h5\n",
      "Epoch 31/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 94.5501 - val_loss: 90.1414\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 88.29740\n",
      "Epoch 32/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 92.4234 - val_loss: 88.0412\n",
      "\n",
      "Epoch 00032: val_loss improved from 88.29740 to 88.04122, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_3_config_8_8_8_4_ts100.h5\n",
      "Epoch 33/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 90.7200 - val_loss: 82.4579\n",
      "\n",
      "Epoch 00033: val_loss improved from 88.04122 to 82.45790, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_3_config_8_8_8_4_ts100.h5\n",
      "Epoch 34/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 88.7611 - val_loss: 86.1355\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 82.45790\n",
      "Epoch 35/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 86.7795 - val_loss: 82.3292\n",
      "\n",
      "Epoch 00035: val_loss improved from 82.45790 to 82.32923, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_3_config_8_8_8_4_ts100.h5\n",
      "Epoch 36/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 85.3486 - val_loss: 80.7478\n",
      "\n",
      "Epoch 00036: val_loss improved from 82.32923 to 80.74780, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_3_config_8_8_8_4_ts100.h5\n",
      "Epoch 37/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 83.8867 - val_loss: 79.0166\n",
      "\n",
      "Epoch 00037: val_loss improved from 80.74780 to 79.01664, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_3_config_8_8_8_4_ts100.h5\n",
      "Epoch 38/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 82.6518 - val_loss: 76.9882\n",
      "\n",
      "Epoch 00038: val_loss improved from 79.01664 to 76.98824, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_3_config_8_8_8_4_ts100.h5\n",
      "Epoch 39/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 81.8211 - val_loss: 76.3292\n",
      "\n",
      "Epoch 00039: val_loss improved from 76.98824 to 76.32922, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_3_config_8_8_8_4_ts100.h5\n",
      "Epoch 40/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 80.2672 - val_loss: 73.1763\n",
      "\n",
      "Epoch 00040: val_loss improved from 76.32922 to 73.17626, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_3_config_8_8_8_4_ts100.h5\n",
      "62/62 [==============================] - 1s 10ms/step\n",
      "Train on 250 samples, validate on 62 samples\n",
      "Epoch 1/40\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 3467.3654 - val_loss: 3506.5283\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3506.52833, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_4_config_8_8_8_4_ts100.h5\n",
      "Epoch 2/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 3408.5602 - val_loss: 3415.5275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00002: val_loss improved from 3506.52833 to 3415.52753, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_4_config_8_8_8_4_ts100.h5\n",
      "Epoch 3/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 3294.0237 - val_loss: 3248.2616\n",
      "\n",
      "Epoch 00003: val_loss improved from 3415.52753 to 3248.26156, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_4_config_8_8_8_4_ts100.h5\n",
      "Epoch 4/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 3098.8318 - val_loss: 2970.0036\n",
      "\n",
      "Epoch 00004: val_loss improved from 3248.26156 to 2970.00365, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_4_config_8_8_8_4_ts100.h5\n",
      "Epoch 5/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 2793.0997 - val_loss: 2576.0042\n",
      "\n",
      "Epoch 00005: val_loss improved from 2970.00365 to 2576.00421, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_4_config_8_8_8_4_ts100.h5\n",
      "Epoch 6/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 2359.0735 - val_loss: 2091.1123\n",
      "\n",
      "Epoch 00006: val_loss improved from 2576.00421 to 2091.11229, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_4_config_8_8_8_4_ts100.h5\n",
      "Epoch 7/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1849.7835 - val_loss: 1556.2157\n",
      "\n",
      "Epoch 00007: val_loss improved from 2091.11229 to 1556.21566, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_4_config_8_8_8_4_ts100.h5\n",
      "Epoch 8/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1298.4923 - val_loss: 1027.1798\n",
      "\n",
      "Epoch 00008: val_loss improved from 1556.21566 to 1027.17985, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_4_config_8_8_8_4_ts100.h5\n",
      "Epoch 9/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 791.8813 - val_loss: 529.8106\n",
      "\n",
      "Epoch 00009: val_loss improved from 1027.17985 to 529.81063, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_4_config_8_8_8_4_ts100.h5\n",
      "Epoch 10/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 348.9918 - val_loss: 212.8971\n",
      "\n",
      "Epoch 00010: val_loss improved from 529.81063 to 212.89711, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_4_config_8_8_8_4_ts100.h5\n",
      "Epoch 11/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 160.8453 - val_loss: 163.1211\n",
      "\n",
      "Epoch 00011: val_loss improved from 212.89711 to 163.12111, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_4_config_8_8_8_4_ts100.h5\n",
      "Epoch 12/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 144.8743 - val_loss: 157.6539\n",
      "\n",
      "Epoch 00012: val_loss improved from 163.12111 to 157.65393, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_4_config_8_8_8_4_ts100.h5\n",
      "Epoch 13/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 121.2584 - val_loss: 125.7081\n",
      "\n",
      "Epoch 00013: val_loss improved from 157.65393 to 125.70815, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_4_config_8_8_8_4_ts100.h5\n",
      "Epoch 14/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 100.7875 - val_loss: 116.0697\n",
      "\n",
      "Epoch 00014: val_loss improved from 125.70815 to 116.06973, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_4_config_8_8_8_4_ts100.h5\n",
      "Epoch 15/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 99.0798 - val_loss: 115.3049\n",
      "\n",
      "Epoch 00015: val_loss improved from 116.06973 to 115.30488, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_4_config_8_8_8_4_ts100.h5\n",
      "Epoch 16/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 97.5152 - val_loss: 113.8687\n",
      "\n",
      "Epoch 00016: val_loss improved from 115.30488 to 113.86867, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_4_config_8_8_8_4_ts100.h5\n",
      "Epoch 17/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 95.4169 - val_loss: 113.6401\n",
      "\n",
      "Epoch 00017: val_loss improved from 113.86867 to 113.64008, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_4_config_8_8_8_4_ts100.h5\n",
      "Epoch 18/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 92.5511 - val_loss: 112.6982\n",
      "\n",
      "Epoch 00018: val_loss improved from 113.64008 to 112.69820, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_4_config_8_8_8_4_ts100.h5\n",
      "Epoch 19/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 90.3076 - val_loss: 111.1581\n",
      "\n",
      "Epoch 00019: val_loss improved from 112.69820 to 111.15805, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_4_config_8_8_8_4_ts100.h5\n",
      "Epoch 20/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 87.7666 - val_loss: 109.8783\n",
      "\n",
      "Epoch 00020: val_loss improved from 111.15805 to 109.87830, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_4_config_8_8_8_4_ts100.h5\n",
      "Epoch 21/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 85.9771 - val_loss: 108.3136\n",
      "\n",
      "Epoch 00021: val_loss improved from 109.87830 to 108.31361, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_4_config_8_8_8_4_ts100.h5\n",
      "Epoch 22/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 83.7945 - val_loss: 107.8038\n",
      "\n",
      "Epoch 00022: val_loss improved from 108.31361 to 107.80381, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_4_config_8_8_8_4_ts100.h5\n",
      "Epoch 23/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 82.0239 - val_loss: 107.6966\n",
      "\n",
      "Epoch 00023: val_loss improved from 107.80381 to 107.69656, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_4_config_8_8_8_4_ts100.h5\n",
      "Epoch 24/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 80.5268 - val_loss: 106.2422\n",
      "\n",
      "Epoch 00024: val_loss improved from 107.69656 to 106.24222, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_4_config_8_8_8_4_ts100.h5\n",
      "Epoch 25/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 78.5408 - val_loss: 104.4617\n",
      "\n",
      "Epoch 00025: val_loss improved from 106.24222 to 104.46167, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_4_config_8_8_8_4_ts100.h5\n",
      "Epoch 26/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 76.7598 - val_loss: 103.2559\n",
      "\n",
      "Epoch 00026: val_loss improved from 104.46167 to 103.25592, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_4_config_8_8_8_4_ts100.h5\n",
      "Epoch 27/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 74.9747 - val_loss: 103.0591\n",
      "\n",
      "Epoch 00027: val_loss improved from 103.25592 to 103.05915, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_4_config_8_8_8_4_ts100.h5\n",
      "Epoch 28/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 73.2761 - val_loss: 102.0206\n",
      "\n",
      "Epoch 00028: val_loss improved from 103.05915 to 102.02058, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_4_config_8_8_8_4_ts100.h5\n",
      "Epoch 29/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 71.6273 - val_loss: 100.2439\n",
      "\n",
      "Epoch 00029: val_loss improved from 102.02058 to 100.24391, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_4_config_8_8_8_4_ts100.h5\n",
      "Epoch 30/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 69.7933 - val_loss: 99.3345\n",
      "\n",
      "Epoch 00030: val_loss improved from 100.24391 to 99.33447, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_4_config_8_8_8_4_ts100.h5\n",
      "Epoch 31/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 68.1332 - val_loss: 99.0219\n",
      "\n",
      "Epoch 00031: val_loss improved from 99.33447 to 99.02188, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_4_config_8_8_8_4_ts100.h5\n",
      "Epoch 32/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 66.3450 - val_loss: 97.9341\n",
      "\n",
      "Epoch 00032: val_loss improved from 99.02188 to 97.93412, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_4_config_8_8_8_4_ts100.h5\n",
      "Epoch 33/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 64.8448 - val_loss: 96.5336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00033: val_loss improved from 97.93412 to 96.53361, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_4_config_8_8_8_4_ts100.h5\n",
      "Epoch 34/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 63.3899 - val_loss: 96.3892\n",
      "\n",
      "Epoch 00034: val_loss improved from 96.53361 to 96.38919, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_4_config_8_8_8_4_ts100.h5\n",
      "Epoch 35/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 62.0993 - val_loss: 94.4810\n",
      "\n",
      "Epoch 00035: val_loss improved from 96.38919 to 94.48105, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_4_config_8_8_8_4_ts100.h5\n",
      "Epoch 36/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 60.1757 - val_loss: 94.3497\n",
      "\n",
      "Epoch 00036: val_loss improved from 94.48105 to 94.34975, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_4_config_8_8_8_4_ts100.h5\n",
      "Epoch 37/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 58.8201 - val_loss: 93.4317\n",
      "\n",
      "Epoch 00037: val_loss improved from 94.34975 to 93.43171, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_4_config_8_8_8_4_ts100.h5\n",
      "Epoch 38/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 57.4865 - val_loss: 92.5017\n",
      "\n",
      "Epoch 00038: val_loss improved from 93.43171 to 92.50172, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_4_config_8_8_8_4_ts100.h5\n",
      "Epoch 39/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 56.4186 - val_loss: 92.5756\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 92.50172\n",
      "Epoch 40/40\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 54.7812 - val_loss: 91.2950\n",
      "\n",
      "Epoch 00040: val_loss improved from 92.50172 to 91.29499, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_4_config_8_8_8_4_ts100.h5\n",
      "62/62 [==============================] - 1s 14ms/step\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import load_model\n",
    "# ten fold\n",
    "from sklearn.model_selection import KFold\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "from datetime import datetime\n",
    "# import tensorflowjs as tfjs\n",
    "\n",
    "sequenceSteps = 100\n",
    "\n",
    "msescores = []\n",
    "model_config = \"config_8_4_2_ts\"+str(sequenceSteps)\n",
    "\n",
    "tempAllVariables = ['arrTemperature0', 'arrTemperature1', 'arrTemperature2', 'arrCPU_load0', 'arrMemory_usage0', 'arrFans_health0', 'arrFans_health1', 'arrFans_health2', 'arrFans_health3', 'arrPower_usage0']\n",
    "allVariables = ['arrTemperature0']\n",
    "timeList = []\n",
    "\n",
    "\n",
    "\n",
    "for feature in allVariables:\n",
    "    print(feature)\n",
    "    X_train, X_test, y_train, Y_test = splitTrainTest(feature)\n",
    "\n",
    "    for training_time in range(0,1):\n",
    "        start_time = datetime.now()\n",
    "        print(start_time)\n",
    "\n",
    "        counter= 0\n",
    "        for trainIdx, testIdx in kfold.split(X_train, y_train):\n",
    "            # create callbacks\n",
    "            model_path = feature+'_training_time_'+str(training_time)+'_best_model_fold_'+str(counter)+\"_\"+model_config+'.h5'\n",
    "            mc = ModelCheckpoint('newModel/'+model_path, monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n",
    "            es = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=1)\n",
    "            # create model\n",
    "            model = createModel(l1Nodes = 8, l2Nodes = 0, d1Nodes = 4, d2Nodes = 2, inputShape= (X_train.shape[1], X_train.shape[2]))\n",
    "            model.fit(X_train[trainIdx], y_train[trainIdx], validation_data=(X_train[testIdx], y_train[testIdx]), batch_size=32, epochs=40, callbacks=[mc, es])\n",
    "            # Done load the best model of this fold\n",
    "            saved_model = load_model('newModel/'+model_path)\n",
    "            msescores.append({'path': 'newModel/'+model_path, 'mse': saved_model.evaluate(X_train[testIdx], y_train[testIdx])})\n",
    "            counter = counter + 1\n",
    "        \n",
    "#             tfjs.converters.save_keras_model(saved_model, 'newModel/'+model_path)\n",
    "\n",
    "        end_time = datetime.now()\n",
    "    \n",
    "        timeList.append({'start': start_time, 'end': end_time, 'time': datetime.timestamp(end_time)-datetime.timestamp(start_time)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start time:  1573029645.002642\n",
      "end time: 1573029752.697422\n",
      "training time:  107.69478011131287\n"
     ]
    }
   ],
   "source": [
    "print ('start time: ',  datetime.timestamp(start_time))\n",
    "print ('end time:', datetime.timestamp(end_time))\n",
    "print ('training time: ', datetime.timestamp(end_time)-datetime.timestamp(start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'path': 'newModel/arrTemperature0_training_time_0_best_model_fold_0_config_8_8_8_4_ts100.h5',\n",
       "  'mse': 3266.9806935143847},\n",
       " {'path': 'newModel/arrTemperature0_training_time_0_best_model_fold_1_config_8_8_8_4_ts100.h5',\n",
       "  'mse': 91.26874614897228},\n",
       " {'path': 'newModel/arrTemperature0_training_time_0_best_model_fold_2_config_8_8_8_4_ts100.h5',\n",
       "  'mse': 79.16638429703251},\n",
       " {'path': 'newModel/arrTemperature0_training_time_0_best_model_fold_3_config_8_8_8_4_ts100.h5',\n",
       "  'mse': 73.1762571027202},\n",
       " {'path': 'newModel/arrTemperature0_training_time_0_best_model_fold_4_config_8_8_8_4_ts100.h5',\n",
       "  'mse': 91.29498635568926}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msescores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_9 (LSTM)                (None, 100, 8)            608       \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 100, 8)            544       \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 8)                 6408      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 7,601\n",
      "Trainable params: 7,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# timeList\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot and see data distribution\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def plotAttrDataOfId(data, compute, features):\n",
    "    plt.figure(figsize=(30, 20))\n",
    "    for i, v in enumerate(features):\n",
    "        plt.subplot(10, 3, i+1)\n",
    "        cDf = df[df['compute']==compute]\n",
    "        plt.plot(cDf['timespan'], cDf[v])\n",
    "        plt.title(v)\n",
    "        plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in np.random.randint(0, len(computes), 3):\n",
    "#     plotAttrDataOfId(df, computes[x], features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotDataDistribution(data, features):\n",
    "    plt.figure(figsize=(30, 10))\n",
    "    for i, v in enumerate(features):\n",
    "        plt.subplot(3, 10, i+1)\n",
    "        sns.distplot(list(data[v].values))\n",
    "        plt.title(v)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotDataDistribution(df, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "print(datetime.now().strftime(\"%H_%M_%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[i for i in range(1,11\n",
    "                 )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (type(X_dfs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
