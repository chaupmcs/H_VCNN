{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test_RUL_FD001_100x50.json', 'train_RUL_FD001_100x50.json', '.DS_Store', 'models', 'test_FD001_100x50.json', 'X_train_HPCC_1_20.json', 'preprocessing', 'train_FD001_100x50.json', 'X_test_HPCC_1_20.json', 'y_test_HPCC_1_20.json', 'y_train_HPCC_1_20.json']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "print(os.listdir(\"..\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"service1906_1506.json\") as of:\n",
    "    data = json.load(of)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "computes = [c for c in data.keys() if c!=\"timespan\"]\n",
    "variables = [v for v in data[computes[0]] if v!='index' and v!='arrJob_scheduling']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check empty array\n",
    "def getEmptyArr(data, c):\n",
    "    cObj = data[c]\n",
    "    cDf = pd.DataFrame()\n",
    "    cDf['compute'] = [c for _ in data['timespan']]\n",
    "    cDf['timespan'] = data['timespan']\n",
    "    for v in variables:\n",
    "        vArr = np.array(cObj[v])\n",
    "        if len(vArr)==0:\n",
    "            print('c=', c)\n",
    "            print('v=', v)\n",
    "for c in computes:\n",
    "    getEmptyArr(data, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addTarget(cDf, predictedVar, predictedStep):\n",
    "    cDf[target] = cDf[predictedVar].shift(-predictedStep)\n",
    "    cDf.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getComputeDf(data, c, predictedVar, predictedStep):\n",
    "    cObj = data[c]\n",
    "    cDf = pd.DataFrame()\n",
    "    cDf['compute'] = [c for _ in data['timespan']]\n",
    "    cDf['timespan'] = data['timespan']\n",
    "    for v in variables:\n",
    "        vArr = np.array(cObj[v])\n",
    "        if len(vArr)==0:\n",
    "            return None\n",
    "        else:\n",
    "            for i in range(len(vArr[0])):\n",
    "                cDf[v+str(i)] = vArr[:, i]\n",
    "    cDf['timespan'] = pd.to_datetime(cDf['timespan'])\n",
    "    addTarget(cDf, predictedVar, predictedStep)\n",
    "    return cDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictedVar = 'arrTemperature0'\n",
    "target = predictedVar + \"_target\"\n",
    "predictedSteps = 4\n",
    "df = pd.concat([x for x in [getComputeDf(data, c, predictedVar, predictedSteps) for c in computes] if type(x)!=\"NoneType\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index().drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [x for x in df.columns if x not in ['compute', 'timespan', 'arrTemperature0_target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot and see data distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotAttrDataOfId(data, compute, features):\n",
    "    plt.figure(figsize=(30, 20))\n",
    "    for i, v in enumerate(features):\n",
    "        plt.subplot(10, 3, i+1)\n",
    "        cDf = df[df['compute']==compute]\n",
    "        plt.plot(cDf['timespan'], cDf[v])\n",
    "        plt.title(v)\n",
    "        plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in np.random.randint(0, len(computes), 3):\n",
    "    plotAttrDataOfId(df, computes[x], features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotDataDistribution(data, features):\n",
    "    plt.figure(figsize=(30, 10))\n",
    "    for i, v in enumerate(features):\n",
    "        plt.subplot(3, 10, i+1)\n",
    "        sns.distplot(list(data[v].values))\n",
    "        plt.title(v)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotDataDistribution(df, features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate sequences\n",
    "May need to fill forward (time sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dfs = []\n",
    "y = []\n",
    "numberOfSequences = 1\n",
    "sequenceSteps = 20\n",
    "# generate training data.\n",
    "for compute in computes:\n",
    "    cDf = df[df['compute']==compute]\n",
    "    if(len(cDf) > sequenceSteps):\n",
    "        randSteps = np.random.randint(0, len(cDf)-sequenceSteps, numberOfSequences)\n",
    "        for randStep in randSteps:\n",
    "            X_dfs.append(cDf.iloc[randStep:randStep+sequenceSteps])\n",
    "            y.append(X_dfs[-1][target].values[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_dfs, X_test_dfs, y_train, y_test = train_test_split(X_dfs, y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the training data to create a scaler\n",
    "train_dfs = pd.concat(X_train_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler().fit(train_dfs[features].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([scaler.transform(item[features].values) for item in X_train_dfs])\n",
    "X_test = np.array([scaler.transform(item[features].values) for item in X_test_dfs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import FileLink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs, json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exportNPArrayToJson(a, fileName):\n",
    "    b = a.tolist()\n",
    "    json.dump(b, codecs.open(fileName, 'w', encoding='utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exportNPArrayToJson(X_train, 'X_train_HPCC_1_20.json')\n",
    "exportNPArrayToJson(X_test, 'X_test_HPCC_1_20.json')\n",
    "exportNPArrayToJson(y_train, 'y_train_HPCC_1_20.json')\n",
    "exportNPArrayToJson(y_test, 'y_test_HPCC_1_20.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FileLink('X_train_HPCC_1_20.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FileLink('X_test_HPCC_1_20.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FileLink('y_train_HPCC_1_20.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FileLink('y_test_HPCC_1_20.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import regularizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "\n",
    "# from keras import backend as K\n",
    "# K.set_session(K.tf.Session(config=K.tf.ConfigProto(intra_op_parallelism_threads=36, inter_op_parallelism_threads=36)))\n",
    "\n",
    "\n",
    "def createModel(l1Nodes, l2Nodes, d1Nodes, d2Nodes, inputShape):\n",
    "    # input layer\n",
    "    lstm1 = LSTM(l1Nodes, input_shape=inputShape, return_sequences=True, kernel_regularizer=regularizers.l2(0.1))\n",
    "    do1 = Dropout(0.2)\n",
    "    \n",
    "    lstm2 = LSTM(l2Nodes, return_sequences=True, kernel_regularizer=regularizers.l2(0.1))\n",
    "    do2 = Dropout(0.2)\n",
    "    \n",
    "    flatten = Flatten()\n",
    "    \n",
    "    dense1 = Dense(d1Nodes, activation='relu')\n",
    "    do3 = Dropout(0.2)\n",
    "    \n",
    "    dense2 = Dense(d2Nodes, activation='relu')\n",
    "    do4 = Dropout(0.2)\n",
    "    \n",
    "    # output layer\n",
    "    outL = Dense(1, activation='relu')\n",
    "    # combine the layers\n",
    "#     layers = [lstm1, do1, lstm2, do2, dense1, do3, dense2, do4, outL]\n",
    "    layers = [lstm1, lstm2, flatten,  dense1, dense2, outL]\n",
    "    # create the model\n",
    "    model = Sequential(layers)\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import load_model\n",
    "# ten fold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "kfold = StratifiedKFold(n_splits=3, shuffle=True)\n",
    "from keras.models import load_model\n",
    "msescores = []\n",
    "counter= 0\n",
    "for trainIdx, testIdx in kfold.split(X_train, y_train):\n",
    "    counter = counter + 1\n",
    "    # create callbacks\n",
    "    model_path = 'best_model_fold'+str(counter)+'.h5'\n",
    "    mc = ModelCheckpoint(model_path, monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n",
    "    es = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=1)\n",
    "    # create model\n",
    "    model = createModel(64, 64, 8, 8, (X_train.shape[1], X_train.shape[2]))\n",
    "    model.fit(X_train[trainIdx], y_train[trainIdx], validation_data=(X_train[testIdx], y_train[testIdx]), batch_size=32, epochs=40, callbacks=[mc, es])\n",
    "    # Done load the best model of this fold\n",
    "    saved_model = load_model(model_path)\n",
    "    msescores.append({'path': model_path, 'mse': saved_model.evaluate(X_train[testIdx], y_train[testIdx])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msescores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for md in msescores:\n",
    "    saved_model = load_model(md['path'])\n",
    "    print(saved_model.evaluate(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = load_model(msescores[np.argmin([sc['mse'] for sc in msescores])]['path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = saved_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = np.array([df[predictedVar].values[-1] for df in X_test_dfs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(50, 10))\n",
    "plt.plot(range(50), predicted[:50], 'x', label='predicted')\n",
    "plt.plot(range(50), baseline[:50], 'v', label='baseline')\n",
    "plt.plot(range(50), y_test[:50], 'o', label='actual')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(y_test, predicted)\n",
    "msebaseline = mean_squared_error(y_test, baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('mse=', mse)\n",
    "print('msebaseline=', msebaseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict_classes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
